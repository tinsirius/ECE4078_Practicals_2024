{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6dd9ad81-acee-4d6b-8ea2-12e4fad1cd0e",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "id": "q-LPBF4o1lwp"
   },
   "source": [
    "# Image classification with Convolutional NN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-8914ba54-a10f-4bb1-894a-2a3264ed247f",
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "id": "LnByvRHF1lwr"
   },
   "source": [
    "## Import all the packages required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-5001bf45-a1e8-4242-aaca-0171f37b258e",
    "deepnote_cell_height": 508,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1629854754890,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 1843,
    "execution_start": 1660798249745,
    "id": "vDt37-Q71lwr",
    "source_hash": "d24662ed"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import time for timekeeping\n",
    "import time\n",
    "\n",
    "# Pytorch (Our Deep Learning Framework)\n",
    "import torch\n",
    "\n",
    "# Torch Data Loader (this will be helful to load image)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# datasets have mnist if using coustom images import io from skimage\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "# stores different optimizors like SGD\n",
    "import torch.optim as optim\n",
    "\n",
    "# Some torch functions that are used multiple times\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed Seed for grading, please don't change the `seed_value`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 12345\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-705b4660-57a8-472e-b10f-8350dfe4fa2c",
    "deepnote_cell_height": 404.515625,
    "deepnote_cell_type": "markdown",
    "id": "YhQiwSs_1lws"
   },
   "source": [
    "## Here is the Multi Layer Perceptron defination you saw.\n",
    "* Any network has an `* __ init __ *` function that initializes all the layers on a NN that require learnable parameters.\n",
    "* A MPL is stack of fully connected layers. In this example we use three fully connected layers named :`fc0`, `fc1` and `fc2`.\n",
    "* Note that each fully connected layer has a number of input neurons that connect to a number of output neurons. \n",
    "* These input and output dimenssions are specified in fc layers initialization.\n",
    "* If a fully connected layers connect to another, its output size = input size of fully connected layer that followes.\n",
    "* Number of paramenters in any fully connected layer is #Input x #Output (and 1 bias per output).\n",
    "\n",
    "## How do we write a forward function?\n",
    "* `torch.flatten(x, start_dim = dim)` converts an image like entity to a vector.\n",
    "* Remeber that you need activations after every fc layer. In this case ReLu. \n",
    "* Notice the `log_softmax` layer at the end. This is a softmax activation function followed by log function as name suggests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-3130f79a-79af-4049-bd7e-a6bd2e3c2e9e",
    "deepnote_cell_height": 490,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1629854756401,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 4,
    "execution_start": 1660798252514,
    "id": "JyXlnDX91lws",
    "source_hash": "5a17dfd5"
   },
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        \n",
    "        # First fully connected layers input image is 28x28 = 784 dim.\n",
    "        self.fc0 = nn.Linear(784, 256) # nparam = 784*256 = 38400\n",
    "        # Two more fully connected layers\n",
    "        self.fc1 = nn.Linear(256, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flattens the image like structure into vectors\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # fully connected layers with activations\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # Outputs are log(p) so softmax followed by log.\n",
    "        #return(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-2a9968e3-7747-4669-b817-47bf7189753a",
    "deepnote_cell_height": 1201.671875,
    "deepnote_cell_type": "markdown",
    "id": "Ss-II79N1lwt"
   },
   "source": [
    "# Our task today is to replace this with a convolutional NN.\n",
    "\n",
    "## Here is how the Lecun Net we want to implement should look like the one in this figure:\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1200/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
    "\n",
    "* Our network now has two blocks each of them has the structure 'convolution followed by relu followed by max pooling', each.\n",
    "* These two blocks replace the `fc0` layer and the relu that follows in the example MLP. \n",
    "* Read inline TODO comments to change the model convolution net for training.\n",
    "\n",
    "**Conv2d is 2D convolutional layer:**\n",
    "   * Initialization reqires the kernal/filter size, number of input channels and number of filters (defining size of output).\n",
    "   * First block has 5x5 convolutional filters. We use 6 of them. Convolutional layer takes a 28x28 image of one channel as input.\n",
    "   * What do you think will be the number of paramenters needed for adding this layer?\n",
    "   * What will be the size after the first 5x5 convolution? Why?\n",
    "   * Second convolution is again 5x5 but this time we use 16 filters as the data we want to encode is more complex.\n",
    "   * Remember to add activation after every convolution!\n",
    "    \n",
    "**MaxPooling2D does subsampling**\n",
    "   * `y = F.max_pool2d(x, k)` command is used to perform $k\\times k$ max pooling of some data x to create a smaller y. \n",
    "   * If the input images to pooling are $2M\\times 2N$, then you will get $M\\times N$ size output.\n",
    "   * We will use $2\\times2$ max pooling after every convolution-relu in this excersise.\n",
    "**We will keep the `fc1` and `fc2` from MLP as it is**\n",
    "\n",
    "# Your job here is to put conv-relu-pooling layers in appropriate order to write a forward function.\n",
    "* **Remeber that `torch.flatten()` converts images to vectors, where will you put the flatten layer now?**\n",
    "* **Think about the number of parameters that you saved by replacing the fc0 of the MLP in this case**\n",
    "\n",
    "# For grading\n",
    "* Do not change the names of the network's attributes (i.e., `self.conv1, self.conv2, self.fc1, self.fc2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-736064b9-5ca3-408d-b813-9416d2c1be27",
    "deepnote_cell_height": 1287,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1629854756401,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 4,
    "execution_start": 1660798253874,
    "id": "r6hz06L91lwt",
    "source_hash": "9e793545"
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        Two convolution layers I am writing the first one\n",
    "        First convolutional layer takes single channel images (batch_size specify the number of images) as input\n",
    "        We have 5x5 convolutions\n",
    "        We have 6 convolutional filter to produce output size 6*28*28 for a single training sample.\n",
    "        structure is : nn.conv2d(number of input channels, number of filters, conv kernal size, stride = 1)\n",
    "        \"\"\"\n",
    "        \n",
    "        #TODO: Add another layer called self.conv1, with Nparam 1*6*5*5 = 150 (+ 5 for bias per output) ---------------\n",
    "        # Replace None with the correct instantiation call\n",
    "        self.conv1 = None\n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        #TODO: Add another layer called self.conv2, 5x5 convolutions 16 filters in total ------------------------------\n",
    "        # Replace None with the correct instantiation call\n",
    "        self.conv2 = None\n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Two more fully connected layers arguments (input size, output size)\n",
    "        \n",
    "        #TODO: What do you think is the input size to fc2 -------------------------------------------------------------\n",
    "        self.fc1 = nn.Linear(None, 84)\n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        # 10 outputs are probability of any specefic digit present in the image\n",
    "        # All sum to one\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input goes to convolution so no need to flatten the image yet\n",
    "        \n",
    "        #TODO: add a 5x5 convolution block (conv1 followed by activation followed by 2x2 max pooling) -----------------\n",
    "        # use conv1 output = self.conv1(input)\n",
    "        # use relu as activation with syntext: output = F.relu(input)\n",
    "        # use max pooling with syntext:  output = F.max_pool2d(input, pooling kernal size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        #TODO: add aother 5x5 convolution block (conv2 followed by activation followed by max pooling) ----------------\n",
    "        \n",
    "        \n",
    "        \n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Think what will be the size now of the image now \n",
    "        # if you don't pad images it is actually (4x4x16)\n",
    "       \n",
    "        #TODO: massage the output so far to feed into fully connect layers --------------------------------------------\n",
    "        # following upon your understanding regarding the size of the output,\n",
    "        # do you need to adjust the forward function in any way?\n",
    "        \n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        #TODO: fully connected layers these remains as is -------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        \n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        #TODO: return output a function of x --------------------------------------------------------------------------\n",
    "        \n",
    "        #ENDTODO ------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-e3ff8d4c-604a-42ea-9431-71be92f44ddf",
    "deepnote_cell_height": 264,
    "deepnote_cell_type": "markdown",
    "id": "5l7Zryfu1lwu"
   },
   "source": [
    "# The rest of the code to train can be used as it is.\n",
    "# We initialize the instance of ConvNet insted of MLP and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00010-01525e55-e4af-4b74-9e11-4036a95870f8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 298.125,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1629854756402,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 146,
    "execution_start": 1660798256004,
    "id": "W3eMyZTJ1lwv",
    "outputId": "14321fd1-d23e-4c95-fd19-d7e2048ef1a7",
    "source_hash": "e59f1625"
   },
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-1b1a8ae2-1596-4f7a-b7c9-88dc6f4de7ee",
    "deepnote_cell_height": 243.34375,
    "deepnote_cell_type": "markdown",
    "id": "3TVDCD6r1lwv"
   },
   "source": [
    "## Dataloaders and Transforms.\n",
    "* dataset.MNIST in pytorch has functionality to download and process MNIST data.\n",
    "* dataloader function usually allows for loading parts of training and test data in minibatches.\n",
    "* It can use somple simple transformations implemented in class transforms that assists training. For example normalizing, resizing or cropping images.\n",
    "* Functionality to dataset, transforms and dataloader classes are usually added to suit new data and training proceedure related to the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00012-9f912402-905d-4783-9cd8-4a22ef0fab26",
    "deepnote_cell_height": 292,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1629854756402,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 52,
    "execution_start": 1660798257976,
    "id": "xMlHuiPJ1lww",
    "source_hash": "e6bc69c9"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Training dataset and training loader.\n",
    "trainset = datasets.MNIST(root='./Practical06_Support/data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "# Test dataset and loader.\n",
    "testset = datasets.MNIST(root='./Practical06_Support/data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-fdeec29d-b55b-4854-a292-22fd3cb02898",
    "deepnote_cell_height": 187.78125,
    "deepnote_cell_type": "markdown",
    "id": "dwz_YRpV1lww"
   },
   "source": [
    "## Here we see sample usage of loading some MNIST training data.\n",
    "* How does out training minibatch looks?\n",
    "* At times simple visualization and print statements allowes for understanding/debugging effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-47071cac-cc5d-4850-a2b4-dc84ba233ed2",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "deepnote_cell_height": 721.125,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     204
    ],
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1629854756971,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 382,
    "execution_start": 1660798259537,
    "id": "twVNxJNF1lww",
    "outputId": "0fc209be-8348-4efc-fd7d-c62159d759a8",
    "source_hash": "3aa1cdf3"
   },
   "outputs": [],
   "source": [
    "def imshow(img, l):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    print('Labels were:')\n",
    "    print(l.reshape(-1,8).numpy())\n",
    "\n",
    "# Load sample data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print('shape of images', images.shape)\n",
    "\n",
    "# display batch\n",
    "imshow(utils.make_grid(images),labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-49c90316-9223-4e46-b58f-29af0d2b2337",
    "deepnote_cell_height": 392.515625,
    "deepnote_cell_type": "markdown",
    "id": "XEGkpIxU1lww"
   },
   "source": [
    "## Loss function for learning.\n",
    "* NLLLoss: The abbrivation NLL stands for Negetive log likelihood. It is however a bit of misnomer as the log is not included in the loss itself but was part of the network defination above. \n",
    "* NOTE: When you want to get the probability/likelihood of an image being of a perticular class you need to remove the log from the forward function and use simple softmax activation at test time. Alternatively simply use `exp` function from torch to invert log and leave the forward function as it is. \n",
    "\n",
    "## Optimizer\n",
    "* pytorch have various optimization rutines (beyond SGD) pre-implemented.\n",
    "* class `optim` will take care of backpropogation with these different optimizations for learning as long as the network defination with appropriate forward function is written correctly.\n",
    "* Here we just use SGD. with learning rate 0.001 and momentum 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-c3f575bf-8ee3-49f6-ac59-1e3bf03e6136",
    "deepnote_cell_height": 130,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1629854756971,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 2,
    "execution_start": 1660798262065,
    "id": "8yLHeLGt1lwx",
    "source_hash": "2bfdeed4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00017-825ee525-1605-45b6-b7ff-c310564aa11a",
    "deepnote_cell_height": 641.25,
    "deepnote_cell_type": "markdown",
    "id": "nxl60KeI1lwx"
   },
   "source": [
    "## This cell of the notebook is now training a network.\n",
    "\n",
    "* First for loop goes throught the entire data 5 times (We run 5 epochs for our training).\n",
    "* The simple steps for training a NN with pytorch are:\n",
    "    * Load data in minibatches.\n",
    "    * Set gradients for all the network parameters to zero (dont forget this)\n",
    "    * Pass data to the NN using a `net.forward()` to compute layer by layer output.\n",
    "        * Intermediate outputs can be returned as extra variables in forward function.\n",
    "    * Compute the loss from the output (remember it is defined above).\n",
    "    * Use `loss.backword()` to compute all the gradients by appropriately applying chain rule! \n",
    "        * It actually know how to differentiate things!!!\n",
    "    * Use `optimizer.step()` updates weights.\n",
    "    \n",
    "## At the end of every epoch usually we check if NN generalizes.\n",
    "* Generalization is critical in learning.\n",
    "* We evaluate the performance of our NN on new data, for which the NN loss was not minimized.\n",
    "* `torch.no_grad()` command forces the following code to not keep track of the gradients as for testing we dont need them.\n",
    "* As no gradients are maintained, the code runs faster!\n",
    "* It a very good practice to make use of `no_grad` function to ensure that we dont accidently minimize loss on the data we are testing the performance on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-a1996bf3-042c-49ab-9049-12ad95aff9d2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_height": 1884,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "executionInfo": {
     "elapsed": 61701,
     "status": "ok",
     "timestamp": 1629854853550,
     "user": {
      "displayName": "Zhongxiang Chen",
      "photoUrl": "",
      "userId": "11440145329065072475"
     },
     "user_tz": -600
    },
    "execution_millis": 73086,
    "execution_start": 1660798375777,
    "id": "EO4ZKWEr1lwx",
    "outputId": "5757cb87-a651-4f66-c856-1d3b933231e4",
    "source_hash": "e9fad686"
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Simply for time keeping\n",
    "    start_time = time.time()\n",
    "    # Loop over all training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute Gradients\n",
    "        loss.backward()\n",
    "        # BackProp\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        # endif\n",
    "    # end for over minibatches epoch finishes\n",
    "    end_time = time.time()\n",
    "\n",
    "    # test the network every epoch on test example\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Test after the epoch finishes (no gradient computation needed)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            # load images and labels\n",
    "            images, labels = data\n",
    "\n",
    "            outputs = net(images)\n",
    "            # note here we take the max of all probability\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "         #end for\n",
    "    #end with\n",
    "    print('Epoch', epoch+1, 'took', end_time-start_time, 'seconds')\n",
    "    print('Accuracy of the network after', epoch+1, 'epochs is' , 100*correct/total)\n",
    "\n",
    "weights = net.state_dict()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading\n",
    "\n",
    "- In this notebook, we are grading 2 things resulting in 6 points maximum: the `weights` variable and class `ConvNet`\n",
    "    - If the structure of class `Convnet` match the solution, you get 3 points\n",
    "    - If your accuracy achieve:\n",
    "        - accuracy <60% -> 0 point\n",
    "        - 60% < accuracy < 90% -> 1 point\n",
    "        - 90% < accuracy < 95% -> 2 points\n",
    "        - accuracy > 90% -> 3 points\n",
    "        \n",
    "<font color=\"red\">**IMPORTANT**</font>: Please only modify in TODO blocks, do not modify anywhere else, it might result in 0 point if you do so! \n",
    "\n",
    "- Notice that this notebook does not use GPU, because the I do parallel grading in each docker instance and I don't have 8 GPUs to spare -> all the training is cpu when I grade.\n",
    "- I give each notebooks a 60 seconds pass for this exercise, so please do not change the number of epochs or being creative and using bigger network to increase your accuracy because it might cross the 60 seconds threshold and result in 0 mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import otter\n",
    "grader = otter.Notebook(tests_dir = \"Practical06_Support/tests\")\n",
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Solution_LeNetClassificationExcersise.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "3804444e-8c7b-4817-bcb9-d4a935332b23",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
